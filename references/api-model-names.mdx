---
title: "API Model Reference"
description: "Complete list of AI models available through the Alter API Router"
---

This reference lists all AI models available through the Alter API Router. Use these model names when making API requests.

## Model Naming Format

All models follow the format: `Provider#Model-name`

For example: `OpenAI#gpt-5`, `Claude#claude-sonnet-4-6`

## OpenAI Models

| Model Name | Description | Context Window |
|------------|-------------|----------------|
| `OpenAI#gpt-5` | Latest GPT-5 model | 128K |
| `OpenAI#gpt-5-mini` | Lightweight GPT-5 | 128K |
| `OpenAI#gpt-5-nano` | Fastest GPT-5 variant | 128K |
| `OpenAI#o3` | Advanced reasoning | 200K |
| `OpenAI#o4-mini` | Efficient reasoning | 200K |

## Claude (Anthropic) Models

| Model Name | Description | Context Window |
|------------|-------------|----------------|
| `Claude#claude-sonnet-4-6` | Latest Claude Sonnet | 200K |
| `Claude#claude-opus-4-6` | Most capable Claude | 200K |
| `Claude#claude-haiku-4-6` | Fast Claude variant | 200K |

## Gemini (Google) Models

| Model Name | Description | Context Window |
|------------|-------------|----------------|
| `Gemini#gemini-2.5-pro` | Most capable Gemini | 1M |
| `Gemini#gemini-2.5-flash` | Fast Gemini | 1M |
| `Gemini#gemini-2.5-flash-lite` | Lightweight Gemini | 1M |

## Mistral Models

| Model Name | Description | Context Window |
|------------|-------------|----------------|
| `Mistral#mistral-large-latest` | Most capable Mistral | 128K |
| `Mistral#mistral-small-latest` | Efficient Mistral | 128K |
| `Mistral#codestral-2501` | Code specialist | 32K |
| `Mistral#pixtral-large-latest` | Vision capable | 128K |

## Perplexity Models

| Model Name | Description | Context Window |
|------------|-------------|----------------|
| `Perplexity#sonar` | Web-aware model | 128K |
| `Perplexity#sonar-pro` | Advanced web search | 128K |
| `Perplexity#sonar-reasoning` | Reasoning with web | 128K |

## Alter Models

| Model Name | Description |
|------------|-------------|
| `Alter#best` | Automatically selects best model |
| `Alter#fair` | Cost-effective option |
| `Alter#light` | Fastest response |

## Usage Examples

### Python
```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://alterhq.com/api/v1"
)

# Use GPT-5
response = client.chat.completions.create(
    model="OpenAI#gpt-5",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

### cURL
```bash
curl https://alterhq.com/api/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "OpenAI#gpt-5",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

## Model Selection Tips

**For Speed**
- `Alter#light`
- `OpenAI#gpt-5-nano`
- `Gemini#gemini-2.5-flash-lite`

**For Quality**
- `Alter#best`
- `OpenAI#gpt-5`
- `Claude#claude-opus-4-6`
- `Gemini#gemini-2.5-pro`

**For Coding**
- `OpenAI#gpt-5`
- `Mistral#codestral-2501`
- `Claude#claude-sonnet-4-6`

**For Vision**
- `OpenAI#gpt-5`
- `Gemini#gemini-2.5-pro`
- `Mistral#pixtral-large-latest`

**For Cost**
- `Alter#fair`
- `Alter#light`
- `OpenAI#gpt-5-nano`